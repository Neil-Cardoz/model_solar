{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9851586,"sourceType":"datasetVersion","datasetId":6045049},{"sourceId":9873115,"sourceType":"datasetVersion","datasetId":6061070},{"sourceId":9873278,"sourceType":"datasetVersion","datasetId":6061195},{"sourceId":163106,"sourceType":"modelInstanceVersion","modelInstanceId":138713,"modelId":161332}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"id\":\"3GwRUfBKo3Cf\",\"outputId\":\"02cccf45-65e6-4bb6-8575-764466a0265b\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:03:58.760618Z\",\"iopub.execute_input\":\"2024-11-12T04:03:58.761021Z\",\"iopub.status.idle\":\"2024-11-12T04:11:19.699436Z\",\"shell.execute_reply.started\":\"2024-11-12T04:03:58.760984Z\",\"shell.execute_reply\":\"2024-11-12T04:11:19.698510Z\"}}\nimport numpy as np\n\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nimport plotly.express as px\n\nimport plotly.graph_objects as go\n\n\n\n\n\n\nelec = pd.read_csv('/kaggle/input/dpeda-data/2107_electrical_data.csv', parse_dates=True)\n\nelec.head()\n\n\n\nirr = pd.read_csv('/kaggle/input/dpeda-data/2107_irradiance_data.csv', parse_dates=True)\n\nirr.head()\n\n\n\nmeter = pd.read_csv('/kaggle/input/dpeda-data/2107_meter_15m_data.csv', parse_dates=True)\n\nmeter.head()\n\n\n\nenv = pd.read_csv('/kaggle/input/dpeda-data/2107_environment_data.csv', parse_dates=True)\n\nenv.head()\n\n\n\nelec['measured_on'] = pd.to_datetime(elec['measured_on'])\n\nirr['measured_on'] = pd.to_datetime(irr['measured_on'])\n\nmeter['measured_on'] = pd.to_datetime(meter['measured_on'])\n\nenv['measured_on'] = pd.to_datetime(env['measured_on'])\n\n\n\nelec = elec[(elec['measured_on'] >= '2017-12-01 00:00:00') & (elec['measured_on'] <= '2023-10-31 23:45:00')]\n\nirr = irr[(irr['measured_on'] >= '2017-12-01 00:00:00') & (irr['measured_on'] <= '2023-10-31 23:45:00')]\n\nmeter = meter[(meter['measured_on'] >= '2017-12-01 00:00:00') & (meter['measured_on'] <= '2023-10-31 23:45:00')]\n\nenv = env[(env['measured_on'] >= '2017-12-01 00:00:00') & (env['measured_on'] <= '2023-10-31 23:45:00')]\n\n\n\nelec[\"DATE\"] = pd.to_datetime(elec[\"measured_on\"]).dt.date\n\nelec[\"TIME\"] = pd.to_datetime(elec[\"measured_on\"]).dt.time\n\nelec['DAY'] = pd.to_datetime(elec['measured_on']).dt.day\n\nelec['MONTH'] = pd.to_datetime(elec['measured_on']).dt.month\n\nelec['WEEK'] = pd.to_datetime(elec['measured_on']).dt.isocalendar().week  # Updated method for weeks in newer versions of pandas\n\nelec['YEAR'] = pd.to_datetime(elec['measured_on']).dt.year\n\n\n\nelec['HOURS'] = pd.to_datetime(elec['TIME'], format='%H:%M:%S').dt.hour\n\nelec['MINUTES'] = pd.to_datetime(elec['TIME'], format='%H:%M:%S').dt.minute\n\nelec['TOTAL MINUTES PASS'] = elec['MINUTES'] + elec['HOURS'] * 60\n\n\n\n# Merging all DataFrames into one DataFrame named 'df'\n\n# Assuming 'measured_on' is the common key to merge on\n\ndf = pd.merge(elec, irr, on='measured_on', how='outer')  # 'outer' join ensures all data is preserved\n\ndf = pd.merge(df, meter, on='measured_on', how='outer')\n\ndf = pd.merge(df, env, on='measured_on', how='outer')\n\n\n\n# prompt: copy df to df_1 and do # Interpolating missing values linearly\n\n# df.interpolate(method='linear', inplace=True)\n\n# for the nal values\n\n\n\ndf_1 = df.copy()\n\ndf_1.interpolate(method='linear', inplace=True)\n\ndf_1.isna().sum()\n\n\n\nrename_dict = {\n\n    'measured_on': 'measured_on',\n\n    'inv_01_dc_current_inv_149579': '01_dc_current',\n\n    'inv_01_dc_voltage_inv_149580': '01_dc_voltage',\n\n    'inv_01_ac_current_inv_149581': '01_ac_current',\n\n    'inv_01_ac_voltage_inv_149582': '01_ac_voltage',\n\n    'inv_01_ac_power_inv_149583': '01_ac_power',\n\n    'inv_02_dc_current_inv_149584': '02_dc_current',\n\n    'inv_02_dc_voltage_inv_149585': '02_dc_voltage',\n\n    'inv_02_ac_current_inv_149586': '02_ac_current',\n\n    'inv_02_ac_voltage_inv_149587': '02_ac_voltage',\n\n    'inv_02_ac_power_inv_149588': '02_ac_power',\n\n    'inv_03_dc_current_inv_149589': '03_dc_current',\n\n    'inv_03_dc_voltage_inv_149590': '03_dc_voltage',\n\n    'inv_03_ac_current_inv_149591': '03_ac_current',\n\n    'inv_03_ac_voltage_inv_149592': '03_ac_voltage',\n\n    'inv_03_ac_power_inv_149593': '03_ac_power',\n\n    'inv_04_dc_current_inv_149594': '04_dc_current',\n\n    'inv_04_dc_voltage_inv_149595': '04_dc_voltage',\n\n    'inv_04_ac_current_inv_149596': '04_ac_current',\n\n    'inv_04_ac_voltage_inv_149597': '04_ac_voltage',\n\n    'inv_04_ac_power_inv_149598': '04_ac_power',\n\n    'inv_05_dc_current_inv_149599': '05_dc_current',\n\n    'inv_05_ac_current_inv_149601': '05_ac_current',\n\n    'inv_05_ac_voltage_inv_149602': '05_ac_voltage',\n\n\n\n    'inv_05_ac_power_inv_149603': '05_ac_power',\n\n    'inv_06_dc_current_inv_149604': '06_dc_current',\n\n    'inv_06_dc_voltage_inv_149605': '06_dc_voltage',\n\n    'inv_06_ac_current_inv_149606': '06_ac_current',\n\n    'inv_06_ac_voltage_inv_149607': '06_ac_voltage',\n\n    'inv_06_ac_power_inv_149608': '06_ac_power',\n\n    'inv_07_dc_current_inv_149609': '07_dc_current',\n\n    'inv_07_dc_voltage_inv_149610': '07_dc_voltage',\n\n    'inv_07_ac_current_inv_149611': '07_ac_current',\n\n    'inv_07_ac_voltage_inv_149612': '07_ac_voltage',\n\n    'inv_07_ac_power_inv_149613': '07_ac_power',\n\n    'inv_08_dc_current_inv_149614': '08_dc_current',\n\n    'inv_08_dc_voltage_inv_149615': '08_dc_voltage',\n\n    'inv_08_ac_current_inv_149616': '08_ac_current',\n\n    'inv_08_ac_voltage_inv_149617': '08_ac_voltage',\n\n    'inv_08_ac_power_inv_149618': '08_ac_power',\n\n    'inv_09_dc_current_inv_149619': '09_dc_current',\n\n    'inv_09_dc_voltage_inv_149620': '09_dc_voltage',\n\n    'inv_09_ac_current_inv_149621': '09_ac_current',\n\n    'inv_09_ac_voltage_inv_149622': '09_ac_voltage',\n\n    'inv_09_ac_power_inv_149623': '09_ac_power',\n\n    'inv_10_dc_current_inv_149624': '10_dc_current',\n\n    'inv_10_dc_voltage_inv_149625': '10_dc_voltage',\n\n    'inv_10_ac_current_inv_149626': '10_ac_current',\n\n    'inv_10_ac_voltage_inv_149627': '10_ac_voltage',\n\n    'inv_10_ac_power_inv_149628': '10_ac_power',\n\n    'inv_11_dc_current_inv_149629': '11_dc_current',\n\n    'inv_11_dc_voltage_inv_149630': '11_dc_voltage',\n\n    'inv_11_ac_current_inv_149631': '11_ac_current',\n\n    'inv_11_ac_voltage_inv_149632': '11_ac_voltage',\n\n    'inv_11_ac_power_inv_149633': '11_ac_power',\n\n    'inv_12_dc_current_inv_149634': '12_dc_current',\n\n    'inv_12_dc_voltage_inv_149635': '12_dc_voltage',\n\n    'inv_12_ac_current_inv_149636': '12_ac_current',\n\n    'inv_12_ac_voltage_inv_149637': '12_ac_voltage',\n\n    'inv_12_ac_power_inv_149638': '12_ac_power',\n\n    'inv_13_dc_current_inv_149639': '13_dc_current',\n\n    'inv_13_dc_voltage_inv_149640': '13_dc_voltage',\n\n    'inv_13_ac_current_inv_149641': '13_ac_current',\n\n    'inv_13_ac_voltage_inv_149642': '13_ac_voltage',\n\n    'inv_13_ac_power_inv_149643': '13_ac_power',\n\n    'inv_14_dc_current_inv_149644': '14_dc_current',\n\n    'inv_14_dc_voltage_inv_149645': '14_dc_voltage',\n\n    'inv_14_ac_current_inv_149646': '14_ac_current',\n\n    'inv_14_ac_voltage_inv_149647': '14_ac_voltage',\n\n    'inv_14_ac_power_inv_149648': '14_ac_power',\n\n    'inv_15_dc_current_inv_149649': '15_dc_current',\n\n    'inv_15_dc_voltage_inv_149650': '15_dc_voltage',\n\n    'inv_15_ac_current_inv_149651': '15_ac_current',\n\n    'inv_15_ac_voltage_inv_149652': '15_ac_voltage',\n\n    'inv_15_ac_power_iinv_149653': '15_ac_power',\n\n    'inv_16_dc_current_inv_149654': '16_dc_current',\n\n    'inv_16_dc_voltage_inv_149655': '16_dc_voltage',\n\n    'inv_16_ac_current_inv_149656': '16_ac_current',\n\n    'inv_16_ac_voltage_inv_149657': '16_ac_voltage',\n\n    'inv_16_ac_power_inv_149658': '16_ac_power',\n\n    'inv_17_dc_current_inv_149659': '17_dc_current',\n\n    'inv_17_dc_voltage_inv_149660': '17_dc_voltage',\n\n    'inv_17_ac_current_inv_149661': '17_ac_current',\n\n    'inv_17_ac_voltage_inv_149662': '17_ac_voltage',\n\n    'inv_17_ac_power_inv_149663': '17_ac_power',\n\n    'inv_18_dc_current_inv_149664': '18_dc_current',\n\n    'inv_18_dc_voltage_inv_149665': '18_dc_voltage',\n\n    'inv_18_ac_current_inv_149666': '18_ac_current',\n\n    'inv_18_ac_voltage_inv_149667': '18_ac_voltage',\n\n    'inv_18_ac_power_inv_149668': '18_ac_power',\n\n    'inv_19_dc_current_inv_149669': '19_dc_current',\n\n    'inv_19_dc_voltage_inv_149670': '19_dc_voltage',\n\n    'inv_19_ac_current_inv_149671': '19_ac_current',\n\n    'inv_19_ac_voltage_inv_149672': '19_ac_voltage',\n\n    'inv_19_ac_power_inv_149673': '19_ac_power',\n\n    'inv_20_dc_current_inv_149674': '20_dc_current',\n\n    'inv_20_dc_voltage_inv_149675': '20_dc_voltage',\n\n    'inv_20_ac_current_inv_149676': '20_ac_current',\n\n    'inv_20_ac_voltage_inv_149677': '20_ac_voltage',\n\n    'inv_20_ac_power_inv_149678': '20_ac_power',\n\n    'inv_21_dc_current_inv_149679': '21_dc_current',\n\n    'inv_21_dc_voltage_inv_149680': '21_dc_voltage',\n\n    'inv_21_ac_current_inv_149681': '21_ac_current',\n\n    'inv_21_ac_voltage_inv_149682': '21_ac_voltage',\n\n    'inv_21_ac_power_inv_149683': '21_ac_power',\n\n    'inv_22_dc_current_inv_149684': '22_dc_current',\n\n    'inv_22_dc_voltage_inv_149685': '22_dc_voltage',\n\n    'inv_22_ac_current_inv_149686': '22_ac_current',\n\n    'inv_22_ac_voltage_inv_149687': '22_ac_voltage',\n\n    'inv_22_ac_power_inv_149688': '22_ac_power',\n\n    'inv_23_dc_current_inv_149689': '23_dc_current',\n\n    'inv_23_dc_voltage_inv_149690': '23_dc_voltage',\n\n    'inv_23_ac_current_inv_149691': '23_ac_current',\n\n    'inv_23_ac_voltage_inv_149692': '23_ac_voltage',\n\n    'inv_23_ac_power_inv_149693': '23_ac_power',\n\n    'inv_24_dc_current_inv_149694': '24_dc_current',\n\n    'inv_24_dc_voltage_inv_149695': '24_dc_voltage',\n\n    'inv_24_ac_current_inv_149696': '24_ac_current',\n\n    'inv_24_ac_voltage_inv_149697': '24_ac_voltage',\n\n    'inv_24_ac_power_inv_149698': '24_ac_power',\n\n    'poa_irradiance_o_149574': 'poa_irradiance',\n\n    'meter_revenue_grade_ac_output_meter_149578': 'revenue_ac_output',\n\n    'ambient_temperature_o_149575': 'ambient_temp',\n\n    'wind_speed_o_149576': 'wind_speed',\n\n    'wind_direction_o_149577': 'wind_direction'\n\n}\n\n\n\n# Apply renaming\n\ndf_1.rename(columns=rename_dict, inplace=True)\n\n\n\n# Drop columns if they exist, otherwise ignore\n\ncolumns_to_drop = [\n\n    '05_dc_current', '05_ac_current',\n\n    '05_ac_voltage',\n\n    '05_ac_power'\n\n]\n\n\n\nfor col in columns_to_drop:\n\n    if col in df_1.columns:\n\n        df_1 = df_1.drop(columns=[col])\n\n\n\n\n\n# Assuming you have a list of inverter numbers (excluding 5)\n\ninverter_numbers = list(range(1, 25))\n\n\n\n# Function to calculate DC power for each inverter based on DC current and voltage\n\ndef calculate_dc_power(row, inverter_num):\n\n    dc_current_col = f\"{inverter_num:02d}_dc_current\"\n\n    dc_voltage_col = f\"{inverter_num:02d}_dc_voltage\"\n\n    return row[dc_current_col] * row[dc_voltage_col]\n\n\n\n# Apply the function across the dataframe for each inverter\n\nfor i in inverter_numbers:\n\n    # Skip the inverter 5 columns since they were dropped\n\n    if i == 5:\n\n        continue\n\n\n\n    # Calculate DC power directly and assign to the new column\n\n    df_1[f\"{i:02d}_dc_power\"] = df_1.apply(calculate_dc_power, axis=1, inverter_num=i)\n\n\n\n# Convert 'ambient_temp' from Fahrenheit to Celsius\n\ndf_1['ambient_temp'] = (df_1['ambient_temp'] - 32) * 5/9\n\n\n\n\n\n# Display a random sample of 5 rows to check the results\n\ndf_1.sample(n=5, random_state=1)\n\n\n\n\n\n\n# %% [markdown]\n# \n\n# %% [code] {\"id\":\"3LbLWbVXpOzi\",\"outputId\":\"ff1fd016-754c-4852-a49b-2c81b995029c\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:19.701411Z\",\"iopub.execute_input\":\"2024-11-12T04:11:19.701762Z\",\"iopub.status.idle\":\"2024-11-12T04:11:19.950182Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:19.701725Z\",\"shell.execute_reply\":\"2024-11-12T04:11:19.949245Z\"}}\n# List of inverter numbers (excluding 5)\n\ninverter_numbers = list(range(1, 25))\n\n\n\n# Iterate through inverter numbers to calculate efficiency\n\nfor i in inverter_numbers:\n\n    # Skip the calculations for inverter 5\n\n    if i == 5:\n\n        continue\n\n\n\n    # Define column names for DC and AC power\n\n    dc_power_col = f\"{i:02d}_dc_power\"\n\n    ac_power_col = f\"{i:02d}_ac_power\"\n\n    efficiency_col = f\"{i:02d}_efficiency %\"\n\n\n\n    # Calculate efficiency (AC/DC ratio) and handle division by zero\n\n    df_1[efficiency_col] = df_1[ac_power_col] / df_1[dc_power_col] *100\n\n    df_1[efficiency_col] = df_1[efficiency_col].replace([np.inf, -np.inf], np.nan)  # Replace infinite values with NaN\n\n    df_1[efficiency_col] = df_1[efficiency_col].fillna(0)  # Optionally fill NaN with 0 (or other desired value)\n\n\n\n# Display the first few rows of the dataframe to verify the new columns\n\ndf_1.head()\n\n\n# %% [code] {\"id\":\"iGIv1hfNpavd\",\"outputId\":\"01b7aa85-8d8e-4bd8-aac5-776341095097\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:19.951355Z\",\"iopub.execute_input\":\"2024-11-12T04:11:19.951661Z\",\"iopub.status.idle\":\"2024-11-12T04:11:21.137951Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:19.951627Z\",\"shell.execute_reply\":\"2024-11-12T04:11:21.137007Z\"}}\n# Identify columns with missing values\n\ncolumns_with_na = df_1.columns[df_1.isna().any()].tolist()\n\n\n\n# Display the list of columns with NA values\n\nprint(\"Columns with NA values:\", columns_with_na)\n\n\n\n# Remove rows with any NA values\n\ndf_1 = df_1.dropna()\n\n\n\n\n\n\n\ncolumns_with_na = df_1.columns[df_1.isna().any()].tolist()\n\n\n\n# Display the list of columns with NA values\n\nprint(\"Columns with NA values:\", columns_with_na)\n\n\n\n# Display the updated dataframe\n\ndf_1.head()\n\n# %% [code] {\"id\":\"LOSzlyaO3Z-s\",\"outputId\":\"3e4c3672-cc51-4007-8bf2-753db1e0d6c0\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:21.139533Z\",\"iopub.execute_input\":\"2024-11-12T04:11:21.140226Z\",\"iopub.status.idle\":\"2024-11-12T04:11:21.426942Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:21.140148Z\",\"shell.execute_reply\":\"2024-11-12T04:11:21.425948Z\"}}\ndf_1.isna().sum()\n\n# %% [markdown]\n# THIS IS ALL OF DF 1\n\n# %% [code] {\"id\":\"YPXGYZNGp5oo\",\"outputId\":\"0eff660c-9822-447f-8329-47316071ef13\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:21.430312Z\",\"iopub.execute_input\":\"2024-11-12T04:11:21.430780Z\",\"iopub.status.idle\":\"2024-11-12T04:11:22.412737Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:21.430742Z\",\"shell.execute_reply\":\"2024-11-12T04:11:22.411552Z\"}}\ndf_18=df_1.copy()\n\ndf_18=df_1[df_1['measured_on'].dt.year == 2018]\n\n\n\ndf_18.head()\n\n# %% [code] {\"id\":\"wRjNJAJH1S4t\",\"outputId\":\"21b2e146-4d8d-4fbc-e94d-dcc826a64bc1\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:22.413901Z\",\"iopub.execute_input\":\"2024-11-12T04:11:22.414221Z\",\"iopub.status.idle\":\"2024-11-12T04:11:22.466667Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:22.414167Z\",\"shell.execute_reply\":\"2024-11-12T04:11:22.465717Z\"}}\ndf_18_jan = df_18[(df_18['measured_on'].dt.month == 1) & (df_18['measured_on'].dt.year == 2018)]\n\ndf_18_jan['measured_on'] = pd.to_datetime(df_18_jan['measured_on'])\n\n\n\ndf_18_jan.sample(n=5, random_state=1)\n\n\n# %% [code] {\"id\":\"h8IyVHS3Y59r\",\"outputId\":\"a76951cb-e3f3-4a46-c865-cf970c8c3f28\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:22.467725Z\",\"iopub.execute_input\":\"2024-11-12T04:11:22.467996Z\",\"iopub.status.idle\":\"2024-11-12T04:11:22.806476Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:22.467966Z\",\"shell.execute_reply\":\"2024-11-12T04:11:22.805537Z\"}}\nfrom sklearn.impute import KNNImputer\n\nimport numpy as np\n\n\n\n# Initialize KNNImputer with n_neighbors=5 (you can change this based on your preference)\n\nknn_imputer = KNNImputer(n_neighbors=5)\n\n\n\n# List of efficiency columns (you can adjust based on your data)\n\nefficiency_cols = [f'{i:02d}_efficiency %' for i in range(1, 25) if i != 5]  # excluding 05_efficiency\n\n\n\n# Apply KNN imputation to the efficiency columns only\n\ndf_18_jan[efficiency_cols] = knn_imputer.fit_transform(df_18_jan[efficiency_cols])\n\n\n\n# Display the dataframe after imputation (showing the first few rows)\n\ndf_18_jan[efficiency_cols].head()\n\n\n# %% [code] {\"id\":\"FkxyBHGKQ8mZ\",\"outputId\":\"4b5ac5b1-e5f4-49ba-aa95-fff2c827fbc2\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:22.807709Z\",\"iopub.execute_input\":\"2024-11-12T04:11:22.808040Z\",\"iopub.status.idle\":\"2024-11-12T04:11:23.181003Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:22.808005Z\",\"shell.execute_reply\":\"2024-11-12T04:11:23.180040Z\"}}\ndf_18_jan.describe()\n\n# %% [code] {\"id\":\"QaOav0EuvQsg\",\"outputId\":\"ef6232ef-53d6-4021-ff46-34ec0e1af109\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:23.182549Z\",\"iopub.execute_input\":\"2024-11-12T04:11:23.183308Z\",\"iopub.status.idle\":\"2024-11-12T04:11:23.234340Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:23.183253Z\",\"shell.execute_reply\":\"2024-11-12T04:11:23.233442Z\"}}\nfrom scipy import stats\n\nimport numpy as np\n\n\n\n# List of efficiency columns for all inverters except 05\n\nefficiency_columns = [f\"{i:02d}_efficiency %\" for i in range(1, 25) if i != 5]\n\n\n\n# Calculate Z-scores for the efficiency columns\n\nz_scores = np.abs(stats.zscore(df_18_jan[efficiency_columns], nan_policy='omit'))\n\n\n\n# Define a threshold for identifying outliers (commonly 3)\n\nthreshold = 3\n\n\n\n# Create a mask to filter out rows with Z-scores greater than the threshold\n\nmask = (z_scores < threshold).all(axis=1)\n\n\n\n# Remove rows with outliers in the efficiency columns\n\ndf_18_jan_clean = df_18_jan[mask]\n\n\n\n# Display the cleaned dataframe\n\ndf_18_jan_clean.head()\n\n\n# %% [code] {\"id\":\"UqCcVd3WRXLg\",\"outputId\":\"e73ab2cf-97d3-44a1-b4f0-f1d8eb528ef0\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:23.235674Z\",\"iopub.execute_input\":\"2024-11-12T04:11:23.236281Z\",\"iopub.status.idle\":\"2024-11-12T04:11:28.512125Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:23.236237Z\",\"shell.execute_reply\":\"2024-11-12T04:11:28.511267Z\"}}\nimport matplotlib.pyplot as plt\n\n\n\n# Extract day numbers from the 'measured_on' column and create a new column\n\ndf_18_jan['day_number'] = df_18_jan['measured_on'].dt.day\n\n\n\n# List of inverter numbers excluding 05\n\ninverter_numbers = [i for i in range(1, 25) if i != 5]\n\n\n\n# Create a plot for the efficiency of each inverter\n\ndef plot_efficiency(df):\n\n    # Create a figure with a large size to fit all the plots\n\n    fig, axes = plt.subplots(nrows=6, ncols=4, figsize=(20, 30))\n\n    axes = axes.flatten()  # Flatten the axes array to easily iterate over it\n\n\n\n    for idx, i in enumerate(inverter_numbers):\n\n        # Column name for the efficiency of the current inverter\n\n        efficiency_col = f\"{i:02d}_efficiency %\"\n\n\n\n        # Plot the efficiency for the current inverter using day numbers on the x-axis\n\n        axes[idx].plot(df['day_number'], df[efficiency_col], color='blue', linewidth=1)\n\n\n\n        # Set title and labels\n\n        axes[idx].set_title(f'Inverter {i} Efficiency loss', fontsize=12, color='blue')\n\n        axes[idx].set_xlabel('Day Number')\n\n        axes[idx].set_ylabel('Efficiency (%)')\n\n\n\n    # Adjust layout for better spacing between plots\n\n    plt.tight_layout()\n\n    plt.show()\n\n\n\n# Call the function to plot efficiency graphs\n\nplot_efficiency(df_18_jan)\n\n\n# %% [code] {\"id\":\"KSODZOw9wNyC\",\"outputId\":\"2c2720d2-70fb-4d00-cd50-0b4b38fe33c5\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:28.513566Z\",\"iopub.execute_input\":\"2024-11-12T04:11:28.513911Z\",\"iopub.status.idle\":\"2024-11-12T04:11:34.061643Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:28.513875Z\",\"shell.execute_reply\":\"2024-11-12T04:11:34.060594Z\"}}\nimport matplotlib.pyplot as plt\n\n\n\n# Ensure the 'day_number' column is extracted from 'measured_on'\n\ndf_18_jan_clean['day_number'] = df_18_jan_clean['measured_on'].dt.day\n\n\n\n# List of inverter numbers excluding 05\n\ninverter_numbers = [i for i in range(1, 25) if i != 5]\n\n\n\n# Create a plot for the efficiency of each inverter\n\ndef plot_efficiency(df):\n\n    # Create a figure with a large size to fit all the plots\n\n    fig, axes = plt.subplots(nrows=6, ncols=4, figsize=(20, 30))\n\n    axes = axes.flatten()  # Flatten the axes array to easily iterate over it\n\n\n\n    for idx, i in enumerate(inverter_numbers):\n\n        # Column name for the efficiency of the current inverter\n\n        efficiency_col = f\"{i:02d}_efficiency %\"\n\n\n\n        # Check if the column exists in the cleaned data before plotting\n\n        if efficiency_col in df.columns:\n\n            # Plot the efficiency for the current inverter using day numbers on the x-axis\n\n            axes[idx].plot(df['day_number'], df[efficiency_col], color='blue', linewidth=1)\n\n\n\n            # Set title and labels\n\n            axes[idx].set_title(f'Inverter {i} Efficiency Loss', fontsize=12, color='blue')\n\n            axes[idx].set_xlabel('Day Number')\n\n            axes[idx].set_ylabel('Efficiency (%)')\n\n        else:\n\n            # If the column does not exist, leave the plot blank\n\n            axes[idx].set_title(f'Inverter {i} Data Missing', fontsize=12, color='red')\n\n            axes[idx].axis('off')  # Hide axis for missing data plots\n\n\n\n    # Adjust layout for better spacing between plots\n\n    plt.tight_layout()\n\n    plt.show()\n\n\n\n# Call the function to plot efficiency graphs for the cleaned data\n\nplot_efficiency(df_18_jan_clean)\n\n\n# %% [code] {\"id\":\"xflOkctHu9gM\",\"outputId\":\"11663824-5b65-4873-89a7-1a931594b491\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:34.062904Z\",\"iopub.execute_input\":\"2024-11-12T04:11:34.063241Z\",\"iopub.status.idle\":\"2024-11-12T04:11:40.465170Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:34.063180Z\",\"shell.execute_reply\":\"2024-11-12T04:11:40.464007Z\"}}\nimport matplotlib.pyplot as plt\n\n\n\n# List of inverter numbers excluding 05\n\ninverter_numbers = [i for i in range(1, 25) if i != 5]\n\n\n\n# Create a plot for output power vs. efficiency for each inverter\n\ndef plot_output_power_vs_efficiency(df):\n\n    # Create a figure with a large size to fit all the plots\n\n    fig, axes = plt.subplots(nrows=6, ncols=4, figsize=(20, 30))\n\n    axes = axes.flatten()  # Flatten the axes array to easily iterate over it\n\n\n\n    for idx, i in enumerate(inverter_numbers):\n\n        # Column names for AC power and efficiency for the current inverter\n\n        ac_power_col = f\"{i:02d}_ac_power\"\n\n        efficiency_col = f\"{i:02d}_efficiency %\"\n\n\n\n        # Plot output power vs. efficiency for the current inverter\n\n        axes[idx].scatter(df[ac_power_col], df[efficiency_col], color='green', alpha=0.7)\n\n\n\n        # Set title and labels\n\n        axes[idx].set_title(f'Inverter {i}: Output Power vs Efficiency', fontsize=12, color='green')\n\n        axes[idx].set_xlabel('AC Power (Output Power)')\n\n        axes[idx].set_ylabel('Efficiency (%)')\n\n\n\n    # Adjust layout for better spacing between plots\n\n    plt.tight_layout()\n\n    plt.show()\n\n\n\n# Call the function to plot output power vs. efficiency graphs\n\nplot_output_power_vs_efficiency(df_18_jan_clean)\n\n\n# %% [code] {\"id\":\"A_Kzfnet2j7Z\",\"outputId\":\"b687f0e3-15bd-4a79-cb46-b1f954cefa0f\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:40.466493Z\",\"iopub.execute_input\":\"2024-11-12T04:11:40.467105Z\",\"iopub.status.idle\":\"2024-11-12T04:11:40.634059Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:40.467068Z\",\"shell.execute_reply\":\"2024-11-12T04:11:40.632964Z\"}}\nimport numpy as np\n\n\n\n# Iterate over the inverter numbers, skipping inverter 05\n\nfor i in range(1, 25):\n\n    if i == 5:\n\n        continue\n\n\n\n    # Construct the column names for DC and AC power\n\n    dc_power_col = f\"{i:02d}_dc_power\"\n\n    ac_power_col = f\"{i:02d}_ac_power\"\n\n\n\n    # Get the DC and AC power values\n\n    dc_power = df_18_jan[df_18_jan[dc_power_col] > 0][dc_power_col].values\n\n    ac_power = df_18_jan[df_18_jan[ac_power_col] > 0][ac_power_col].values\n\n\n\n    if len(dc_power) > 0 and len(ac_power) > 0:  # Ensure there is data available for the inverter\n\n        # Calculate the efficiency (AC/DC ratio)\n\n        solar_plant_eff = (np.max(ac_power) / np.max(dc_power)) * 100\n\n\n\n        print(f\"Power ratio AC/DC (Efficiency) for Inverter {i:02d}: {solar_plant_eff:0.3f} %\")\n\n    else:\n\n        print(f\"No valid data for Inverter {i:02d}\")\n\n\n# %% [code] {\"id\":\"JwKY6lJjEe4q\",\"outputId\":\"fdc736ec-17b0-45b6-edfc-744812cc4b8c\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:40.639644Z\",\"iopub.execute_input\":\"2024-11-12T04:11:40.639958Z\",\"iopub.status.idle\":\"2024-11-12T04:11:52.754104Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:40.639925Z\",\"shell.execute_reply\":\"2024-11-12T04:11:52.753187Z\"}}\nimport matplotlib.pyplot as plt\n\n\n\n# Select the relevant columns for inverter 01's DC power and ambient temperature\n\ndf_temp_dc_01 = df_18_jan[['TIME', 'DATE', '01_dc_power', 'ambient_temp']]\n\n\n\n# Create pivot tables for both DC power and ambient temperature\n\nsolar_dc_01 = df_temp_dc_01.pivot_table(values='01_dc_power', index='TIME', columns='DATE')\n\nambient_temp_01 = df_temp_dc_01.pivot_table(values='ambient_temp', index='TIME', columns='DATE')\n\n# Define the Daywise plot function\n\ndef Daywise_plot(data_dc=None, data_temp=None, row=None, col=None, title=''):\n\n    cols = data_dc.columns  # Get all the columns for plotting\n\n\n\n    # Calculate total number of subplots needed\n\n    num_subplots = len(cols) * 2\n\n\n\n    # Calculate rows and columns to fit all subplots\n\n\n\n    row = int(np.ceil(num_subplots / col)) # Calculate necessary rows\n\n\n\n\n\n\n    gp = plt.figure(figsize=(20, 40))  # Adjust figure size as needed\n\n\n\n    # Adjust subplots spacing\n\n    gp.subplots_adjust(wspace=0.2, hspace=0.5)\n\n\n\n    for i in range(1, len(cols) + 1):\n\n        # Plot DC power for inverter 01\n\n        ax1 = gp.add_subplot(row, col, 2*i-1)  # Create subplot for DC power\n\n        data_dc[cols[i - 1]].plot(ax=ax1, color='red')\n\n        ax1.set_title('{} - DC {}'.format(title, cols[i - 1]), color='blue')\n\n\n\n        # Plot Ambient Temperature\n\n        ax2 = gp.add_subplot(row, col, 2*i)  # Create subplot for Ambient Temperature\n\n        data_temp[cols[i - 1]].plot(ax=ax2, color='green')\n\n        ax2.set_title('{} - AC {}'.format(title, cols[i - 1]), color='blue')\n\n\n\n# Call the function for Daywise plotting with both DC power and ambient temperature\n\nDaywise_plot(data_dc=solar_dc_01, data_temp=ambient_temp_01, row=6, col=6)  # Adjust row and col for better layout # Increased column count for better layout\n\n# %% [code] {\"id\":\"XxcWSpBeGbRa\",\"outputId\":\"7d1fb981-4458-43f6-e65c-7286528f0cd5\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:52.755333Z\",\"iopub.execute_input\":\"2024-11-12T04:11:52.755665Z\",\"iopub.status.idle\":\"2024-11-12T04:11:55.613275Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:52.755629Z\",\"shell.execute_reply\":\"2024-11-12T04:11:55.612223Z\"}}\nimport pandas as pd\n\ndf_1_Y = df_1.copy()\n\ndf_1_Y['measured_on'] = pd.to_datetime(df_1_Y['measured_on'])\n\n\n\ndf_1_Y.set_index('measured_on', inplace=True)\n\n# Exclude non-numeric columns from the mean calculation\n\ndf_1_Y = df_1_Y.resample('Y').mean(numeric_only=True)\n\ndf_1_Y\n\n# %% [code] {\"id\":\"GOItA4n3zjSB\",\"outputId\":\"f6a5ff58-f734-417e-fb66-f59da1e4aadf\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:55.614496Z\",\"iopub.execute_input\":\"2024-11-12T04:11:55.614821Z\",\"iopub.status.idle\":\"2024-11-12T04:11:56.184910Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:55.614787Z\",\"shell.execute_reply\":\"2024-11-12T04:11:56.183855Z\"}}\nimport matplotlib.pyplot as plt\n\n\n\n# Assuming 'irradiance' and 'AC output' are the relevant column names\n\nirr_col = 'poa_irradiance'  # Replace with the actual column name for irradiance in your data if different\n\nac_output_col = 'revenue_ac_output'  # Replace with the actual column name for AC output in your data if different\n\n\n\n# Create the plot\n\nfig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 10))\n\n\n\n# Plot the irradiance\n\naxes[0].plot(df_1_Y.index.year, df_1_Y[irr_col], marker='o', linestyle='-', color='orange', linewidth=2)\n\naxes[0].set_title('Yearly Average Irradiance', fontsize=14, color='orange')\n\naxes[0].set_xlabel('Year')\n\naxes[0].set_ylabel('Irradiance')\n\naxes[0].grid(visible=True)\n\n\n\n# Plot the AC output power\n\naxes[1].plot(df_1_Y.index.year, df_1_Y[ac_output_col], marker='o', linestyle='-', color='blue', linewidth=2)\n\naxes[1].set_title('Yearly Average AC Output Power', fontsize=14, color='blue')\n\naxes[1].set_xlabel('Year')\n\naxes[1].set_ylabel('AC Output Power')\n\naxes[1].grid(visible=True)\n\n\n\n# Adjust layout for better spacing\n\nplt.tight_layout()\n\nplt.show()\n\n\n# %% [code] {\"id\":\"GYLh1WH1B9zg\",\"outputId\":\"a87dd7dc-d58d-4023-e338-dfe50adc015f\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:56.186630Z\",\"iopub.execute_input\":\"2024-11-12T04:11:56.187080Z\",\"iopub.status.idle\":\"2024-11-12T04:11:56.226682Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:56.187031Z\",\"shell.execute_reply\":\"2024-11-12T04:11:56.225671Z\"}}\ndf_1.head()\n\n# %% [code] {\"id\":\"qTHwzowoAbf6\",\"outputId\":\"433b3678-55b8-48a4-c403-562566b1bfcd\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:56.227755Z\",\"iopub.execute_input\":\"2024-11-12T04:11:56.228039Z\",\"iopub.status.idle\":\"2024-11-12T04:11:57.440093Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:56.228008Z\",\"shell.execute_reply\":\"2024-11-12T04:11:57.439088Z\"}}\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\n\n\n# Ensure 'measured_on' is a datetime type\n\ndf_1['measured_on'] = pd.to_datetime(df_1['measured_on'])\n\n\n\n# Sum the AC power daily\n\ndf_1['sum_ac'] = df_1.groupby(df_1['measured_on'].dt.date)['revenue_ac_output'].transform('sum')\n\n\n\n# Filter data for the years 2017 to 2023\n\nyears = range(2017, 2024)\n\n\n\n# Initialize a list to store the largest value of each year\n\nlargest_values_of_years = []\n\n\n\n# Loop through the years 2017 to 2023\n\nfor year in years:\n\n    # Filter data for the specific year\n\n    df_year = df_1[df_1['measured_on'].dt.year == year]\n\n\n\n    # Get the maximum value of 'sum_ac' for the year\n\n    max_value = df_year['sum_ac'].max()\n\n\n\n    # Append the maximum value of the year to the list\n\n    largest_values_of_years.append(max_value)\n\n\n\n# Plot the histogram with the years on the x-axis\n\nplt.figure(figsize=(10, 6))\n\nplt.bar(years, largest_values_of_years, color='blue', edgecolor='black')\n\nplt.title('AC Power for Each Year', fontsize=14)\n\nplt.xlabel('Year', fontsize=12)\n\nplt.ylabel(' Sum of AC Power', fontsize=12)\n\nplt.xticks(years)  # Set x-axis to show the years\n\nplt.show()\n\n\n# %% [code] {\"id\":\"fc19k7qbEgay\",\"outputId\":\"b8856fb4-bd42-4e91-9dbf-496bc533cb61\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:57.441277Z\",\"iopub.execute_input\":\"2024-11-12T04:11:57.441596Z\",\"iopub.status.idle\":\"2024-11-12T04:11:58.565775Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:57.441561Z\",\"shell.execute_reply\":\"2024-11-12T04:11:58.564795Z\"}}\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\n\n\n# Ensure 'measured_on' is a datetime type\n\ndf_1['measured_on'] = pd.to_datetime(df_1['measured_on'])\n\n\n\n# Sum the irradiance daily\n\ndf_1['sum_irradiance'] = df_1.groupby(df_1['measured_on'].dt.date)['poa_irradiance'].transform('sum')\n\n\n\n# Filter data for the years 2017 to 2023\n\nyears = range(2017, 2024)\n\n\n\n# Initialize a list to store the largest value of irradiance for each year\n\nlargest_irradiance_values = []\n\n\n\n# Loop through the years 2017 to 2023\n\nfor year in years:\n\n    # Filter data for the specific year\n\n    df_year = df_1[df_1['measured_on'].dt.year == year]\n\n\n\n    # Get the maximum value of 'sum_irradiance' for the year\n\n    max_irradiance_value = df_year['sum_irradiance'].max()\n\n\n\n    # Append the maximum value of the year to the list\n\n    largest_irradiance_values.append(max_irradiance_value)\n\n\n\n# Plot the histogram with the years on the x-axis\n\nplt.figure(figsize=(10, 6))\n\nplt.bar(years, largest_irradiance_values, color='orange', edgecolor='black')\n\nplt.title('Largest amt of Irradiance for Each Year', fontsize=14)\n\nplt.xlabel('Year', fontsize=12)\n\nplt.ylabel('total amt of Irradiance in a day', fontsize=12)\n\nplt.xticks(years)  # Set x-axis to show the years\n\nplt.show()\n\n\n# %% [code] {\"id\":\"vSVdhcfBQSGY\",\"outputId\":\"a3b341b8-1945-4bac-b1ac-76dd0c35cd85\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:58.567287Z\",\"iopub.execute_input\":\"2024-11-12T04:11:58.567704Z\",\"iopub.status.idle\":\"2024-11-12T04:11:59.316480Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:58.567659Z\",\"shell.execute_reply\":\"2024-11-12T04:11:59.315420Z\"}}\n# prompt: PLOT THE LINEPLOT OF AC POWER DC POWER EFFICICNY TEMP  AND WIDNSPEED OF 10-01-18\n\n\n\n# Filter data for 10-01-2018\n\ndf_2018_08_10 = df_1[df_1['measured_on'].dt.date == pd.to_datetime('2018-10-08').date()]\n\n\n\n# Plot the lineplot\n\nplt.figure(figsize=(15, 8))\n\n\n\n\n\nplt.plot(df_2018_08_10['measured_on'], df_2018_08_10['ambient_temp'], label='Ambient Temperature')\n\nplt.plot(df_2018_08_10['measured_on'], df_2018_08_10['wind_speed'], label='Wind Speed')\n\n\n\n\n\nplt.xlabel('Time')\n\nplt.ylabel('Values')\n\nplt.title('Line Plot for 10-01-2018')\n\nplt.legend()\n\nplt.grid(True)\n\nplt.show()\n\n# %% [code] {\"id\":\"qwht41weU_D4\",\"outputId\":\"5f902adf-7cf9-4bef-a0c5-ca8b0fe9d618\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:59.317976Z\",\"iopub.execute_input\":\"2024-11-12T04:11:59.318841Z\",\"iopub.status.idle\":\"2024-11-12T04:11:59.709597Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:59.318794Z\",\"shell.execute_reply\":\"2024-11-12T04:11:59.708649Z\"}}\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\n\n\n\n# Assuming 'df_2018_01_10' is your DataFrame\n\n# and 'measured_on' and '01_efficiency' are your columns\n\n\n\nplt.figure(figsize=(15, 8))  # Adjust figure size if needed\n\n\n\nplt.plot(df_2018_08_10['measured_on'], df_2018_08_10['01_efficiency %'], label='Efficiency (Inv 01)')\n\n\n\nplt.xlabel('Time')  # Set x-axis label\n\nplt.ylabel('Efficiency (Inv 01)')  # Set y-axis label\n\nplt.title('Inverter 01 Efficiency on 10-01-2018')  # Set title\n\nplt.legend()  # Display legend\n\nplt.grid(True)  # Add grid lines\n\n\n\nplt.show()  # Display the plot\n\n# %% [code] {\"id\":\"aJxdBk7e4xvR\",\"outputId\":\"4b362986-3532-4d6e-9e3d-976f027a8f2f\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:11:59.711433Z\",\"iopub.execute_input\":\"2024-11-12T04:11:59.711825Z\",\"iopub.status.idle\":\"2024-11-12T04:12:00.356063Z\",\"shell.execute_reply.started\":\"2024-11-12T04:11:59.711782Z\",\"shell.execute_reply\":\"2024-11-12T04:12:00.355093Z\"}}\nimport matplotlib.pyplot as plt\n\n\n\n# Replace these with the actual column names for irradiance and AC output in your dataframe\n\nirr_col = 'poa_irradiance'  # Update with the actual column name for irradiance\n\nac_output_col = 'revenue_ac_output'  # Update with the actual column name for AC output\n\n\n\n# Create the plot with two subplots, one above the other\n\nfig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 10))\n\n\n\n# Plot the irradiance\n\naxes[0].plot(df_2018_08_10['measured_on'], df_2018_08_10[irr_col], color='orange', linestyle='-', linewidth=2)\n\naxes[0].set_title('Irradiance over Time', fontsize=14, color='orange')\n\naxes[0].set_xlabel('Date')\n\naxes[0].set_ylabel('Irradiance')\n\naxes[0].grid(visible=True)\n\n\n\n# Plot the AC output power\n\naxes[1].plot(df_2018_08_10['measured_on'], df_2018_08_10[ac_output_col], color='blue', linestyle='-', linewidth=2)\n\naxes[1].set_title('AC Output Power over Time', fontsize=14, color='blue')\n\naxes[1].set_xlabel('Date')\n\naxes[1].set_ylabel('AC Output Power')\n\naxes[1].grid(visible=True)\n\n\n\n# Adjust layout for better spacing\n\nplt.tight_layout()\n\nplt.show()\n\n\n# %% [code] {\"id\":\"rP1YtzMX4Yon\",\"outputId\":\"6a09cf3a-fbb5-4846-f351-c4ff16fb4f8e\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:12:00.357302Z\",\"iopub.execute_input\":\"2024-11-12T04:12:00.357621Z\",\"iopub.status.idle\":\"2024-11-12T04:12:01.076980Z\",\"shell.execute_reply.started\":\"2024-11-12T04:12:00.357587Z\",\"shell.execute_reply\":\"2024-11-12T04:12:01.075841Z\"}}\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\n\n\n# List of inverter numbers excluding 05 (if necessary)\n\ninverter_numbers = [i for i in range(1, 25) if i != 5]\n\n\n\n# Create a list to store the efficiency columns for each inverter\n\nefficiency_columns = [f\"{i:02d}_efficiency %\" for i in inverter_numbers]\n\n\n\n# Set up the plot (multiple boxplots)\n\nplt.figure(figsize=(20, 10))\n\n\n\n# Create a boxplot for each inverter's efficiency\n\nsns.boxplot(data=df_2018_08_10[efficiency_columns])\n\n\n\n# Set title and labels\n\nplt.title('Efficiency Boxplot for All Inverters on 2018-10-08', fontsize=16)\n\nplt.xlabel('Inverter Number', fontsize=14)\n\nplt.ylabel('Efficiency (%)', fontsize=14)\n\n\n\n# Display the plot\n\nplt.xticks(ticks=range(len(efficiency_columns)), labels=[f\"Inverter {i}\" for i in inverter_numbers], rotation=90)\n\nplt.tight_layout()\n\nplt.show()\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:20:11.403434Z\",\"iopub.execute_input\":\"2024-11-12T04:20:11.403854Z\",\"iopub.status.idle\":\"2024-11-12T04:28:41.658727Z\",\"shell.execute_reply.started\":\"2024-11-12T04:20:11.403815Z\",\"shell.execute_reply\":\"2024-11-12T04:28:41.657844Z\"}}\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nimport matplotlib.pyplot as plt\nimport io\nimport base64\nimport dash\nfrom dash import dcc, html\nfrom dash.dependencies import Input, Output\n\n# Assuming df_1 is your dataset\n# Define the columns\nefficiency_cols = [f\"{i:02d}_efficiency %\" for i in range(1, 25) if i != 5]\nfeature_cols = efficiency_cols + ['poa_irradiance', 'ambient_temp', 'wind_speed']\ntarget_col = 'revenue_ac_output'\n\n# Drop rows with missing values in the selected columns\ndf_lstm = df_1[feature_cols + [target_col]].dropna()\n\n# Normalize the features and target separately\nscaler_features = MinMaxScaler(feature_range=(0, 1))\nscaler_target = MinMaxScaler(feature_range=(0, 1))\n\nnormalized_features = scaler_features.fit_transform(df_lstm[feature_cols])\nnormalized_target = scaler_target.fit_transform(df_lstm[[target_col]])\n\n# Create sequences for LSTM input\nsequence_length = 30  # Length of sequences (e.g., last 30 timesteps)\nX = []\ny = []\n\nfor i in range(sequence_length, len(normalized_features)):\n    X.append(normalized_features[i-sequence_length:i])  # Past `sequence_length` timesteps for input\n    y.append(normalized_target[i])  # Target at the next timestep\n\nX = np.array(X)\ny = np.array(y)\n\n# Manually split data into training and testing sets (e.g., 80% for training and 20% for testing)\ntrain_size = int(0.8 * len(X))\nX_train, X_test = X[:train_size], X[train_size:]\ny_train, y_test = y[:train_size], y[train_size:]\n\n# Build the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\nmodel.add(LSTM(32))\nmodel.add(Dense(1))  # Output layer for predicting `revenue_ac_output`\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n\n# Make predictions\npredicted_values = model.predict(X_test)\npredicted_values = scaler_target.inverse_transform(predicted_values)  # Inverse transform to original scale\ny_test_original = scaler_target.inverse_transform(y_test)  # Inverse transform for comparison\n\n# Plot the results\nplt.figure(figsize=(12, 6))\nplt.plot(y_test_original, label='Actual Revenue AC Output', color='blue')\nplt.plot(predicted_values, label='Predicted Revenue AC Output', color='red')\nplt.title('LSTM Predictions vs Actual Revenue AC Output')\nplt.xlabel('Time Step')\nplt.ylabel('Revenue AC Output')\nplt.legend()\n\n# Save the plot to a BytesIO object\nimg_bytes = io.BytesIO()\nplt.savefig(img_bytes, format='png')\nimg_bytes.seek(0)\nimg_base64 = base64.b64encode(img_bytes.read()).decode('utf-8')\n\n# Create Dash App\napp = dash.Dash(__name__)\n\napp.layout = html.Div(children=[\n    html.H1('LSTM Forecasting Model for Revenue AC Output'),\n    html.Div([\n        html.H3('Predictions vs Actual Revenue AC Output'),\n        html.Img(src=f\"data:image/png;base64,{img_base64}\")\n    ]),\n    html.Div([\n        dcc.Graph(\n            id='time-series-plot',\n            figure={\n                'data': [\n                    {'x': list(range(len(y_test_original))), 'y': y_test_original.flatten(), 'type': 'line', 'name': 'Actual'},\n                    {'x': list(range(len(predicted_values))), 'y': predicted_values.flatten(), 'type': 'line', 'name': 'Predicted'},\n                ],\n                'layout': {\n                    'title': 'LSTM Predictions vs Actual Revenue AC Output',\n                    'xaxis': {'title': 'Time Step'},\n                    'yaxis': {'title': 'Revenue AC Output'},\n                    'legend': {'x': 0, 'y': 1}\n                }\n            }\n        )\n    ])\n])\n\n# Run the app\nif __name__ == '__main__':\n    app.run_server(debug=True)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:19:47.129356Z\",\"iopub.execute_input\":\"2024-11-12T04:19:47.129755Z\",\"iopub.status.idle\":\"2024-11-12T04:20:01.747369Z\",\"shell.execute_reply.started\":\"2024-11-12T04:19:47.129718Z\",\"shell.execute_reply\":\"2024-11-12T04:20:01.746184Z\"}}\n!pip install dash\n\n# %% [code] {\"id\":\"2HD_EA8TWbGd\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:12:01.078474Z\",\"iopub.execute_input\":\"2024-11-12T04:12:01.078961Z\",\"iopub.status.idle\":\"2024-11-12T04:13:41.781007Z\",\"shell.execute_reply.started\":\"2024-11-12T04:12:01.078916Z\",\"shell.execute_reply\":\"2024-11-12T04:13:41.779423Z\"}}\nimport numpy as np\n\nimport pandas as pd\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import LSTM, Dense\n\nimport matplotlib.pyplot as plt\n\n\n\n# Extract efficiency columns\n\nefficiency_cols = [f\"{i:02d}_efficiency %\" for i in range(1, 25) if i != 5]\n\nfeature_cols = efficiency_cols + ['poa_irradiance', 'ambient_temp', 'wind_speed']\n\ntarget_col = 'revenue_ac_output'\n\n\n\n# Drop rows with missing values in the selected columns\n\ndf_lstm = df_1[feature_cols + [target_col]].dropna()\n\n\n\n# Normalize the features and target separately\n\nscaler_features = MinMaxScaler(feature_range=(0, 1))\n\nscaler_target = MinMaxScaler(feature_range=(0, 1))\n\n\n\nnormalized_features = scaler_features.fit_transform(df_lstm[feature_cols])\n\nnormalized_target = scaler_target.fit_transform(df_lstm[[target_col]])\n\n\n\n# Create sequences for LSTM input\n\nsequence_length = 48  # Length of sequences (e.g., last 30 timesteps)\n\nX = []\n\ny = []\n\n\n\nfor i in range(sequence_length, len(normalized_features)):\n\n    X.append(normalized_features[i-sequence_length:i])  # Past `sequence_length` timesteps for input\n\n    y.append(normalized_target[i])  # Target at the next timestep\n\n\n\nX = np.array(X)\n\ny = np.array(y)\n\n\n\n# Manually split data into training and testing sets (e.g., 80% for training and 20% for testing)\n\ntrain_size = int(0.8 * len(X))\n\nX_train, X_test = X[:train_size], X[train_size:]\n\ny_train, y_test = y[:train_size], y[train_size:]\n\n\n\n# Build the LSTM model\n\nmodel = Sequential()\nmodel.add(LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n\nmodel.add(LSTM(32))\n\nmodel.add(Dense(1))\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Callbacks for learning rate adjustment and early stopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\nmodel.fit(X_train, y_train, epochs=50, batch_size=6, validation_data=(X_test, y_test),\n          verbose=1, callbacks=[lr_scheduler, early_stopping])\n\n\n\n# Make predictions\n\npredicted_values = model.predict(X_test)\n\npredicted_values = scaler_target.inverse_transform(predicted_values)  # Inverse transform to original scale\n\ny_test_original = scaler_target.inverse_transform(y_test)  # Inverse transform for comparison\n\n\n\n# Plot the results\n\nplt.figure(figsize=(12, 6))\n\nplt.lineplot(y_test_original, label='Actual Revenue AC Output', color='blue')\n\nplt.lineplot(predicted_values, label='Predicted Revenue AC Output', color='red')\n\nplt.title('LSTM Predictions vs Actual Revenue AC Output')\n\nplt.xlabel('Time Step')\n\nplt.ylabel('Revenue AC Output')\n\nplt.legend()\n\nplt.show()\n\n\n# %% [code] {\"id\":\"Snesg-A6WbIi\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:13:41.782227Z\",\"iopub.status.idle\":\"2024-11-12T04:13:41.782736Z\",\"shell.execute_reply.started\":\"2024-11-12T04:13:41.782477Z\",\"shell.execute_reply\":\"2024-11-12T04:13:41.782502Z\"}}\n# Plot the results as a scatter plot\nplt.figure(figsize=(12, 6))\n\n# Scatter plot for actual values\nplt.scatter(range(len(y_test_original)), y_test_original, label='Actual Revenue AC Output', color='blue', alpha=0.6)\n\n# Scatter plot for predicted values\nplt.scatter(range(len(predicted_values)), predicted_values, label='Predicted Revenue AC Output', color='red', alpha=0.6)\n\n# Add title and labels\nplt.title('LSTM Predictions vs Actual Revenue AC Output')\nplt.xlabel('Time Step')\nplt.ylabel('Revenue AC Output')\n\n# Display the legend\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n# %% [code] {\"id\":\"C7FVUM20WbKq\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:13:41.784124Z\",\"iopub.status.idle\":\"2024-11-12T04:13:41.784625Z\",\"shell.execute_reply.started\":\"2024-11-12T04:13:41.784372Z\",\"shell.execute_reply\":\"2024-11-12T04:13:41.784397Z\"}}\nmodel.save('solar_panel_lstm_model.h5')  # Save in .h5 format\n\n# %% [code] {\"id\":\"Zssdt1NbWbMr\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:13:41.786836Z\",\"iopub.status.idle\":\"2024-11-12T04:13:41.787223Z\",\"shell.execute_reply.started\":\"2024-11-12T04:13:41.787022Z\",\"shell.execute_reply\":\"2024-11-12T04:13:41.787040Z\"}}\nimport numpy as np\n\nimport pandas as pd\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import LSTM, Dense\n\nimport matplotlib.pyplot as plt\n\n\n\n# Extract efficiency columns\n\nefficiency_cols = [f\"{i:02d}_efficiency %\" for i in range(1, 25) if i != 5]\n\nfeature_cols = efficiency_cols + ['poa_irradiance', 'ambient_temp', 'wind_speed']\n\ntarget_col = 'revenue_ac_output'\n\n\n\n# Drop rows with missing values in the selected columns\n\ndf_lstm = df_1[feature_cols + [target_col]].dropna()\n\n\n\n# Normalize the features and target separately\n\nscaler_features = MinMaxScaler(feature_range=(0, 1))\n\nscaler_target = MinMaxScaler(feature_range=(0, 1))\n\n\n\nnormalized_features = scaler_features.fit_transform(df_lstm[feature_cols])\n\nnormalized_target = scaler_target.fit_transform(df_lstm[[target_col]])\n\n\n\n# Create sequences for LSTM input\n\nsequence_length = 48  # Length of sequences (e.g., last 30 timesteps)\n\nX = []\n\ny = []\n\n\n\nfor i in range(sequence_length, len(normalized_features)):\n\n    X.append(normalized_features[i-sequence_length:i])  # Past `sequence_length` timesteps for input\n\n    y.append(normalized_target[i])  # Target at the next timestep\n\n\n\nX = np.array(X)\n\ny = np.array(y)\n\n\n\n# Manually split data into training and testing sets (e.g., 80% for training and 20% for testing)\n\ntrain_size = int(0.8 * len(X))\n\nX_train, X_test = X[:train_size], X[train_size:]\n\ny_train, y_test = y[:train_size], y[train_size:]\n\n\n\n# Build the LSTM model\n\nmodel = Sequential()\nmodel.add(LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n\nmodel.add(LSTM(32))\n\nmodel.add(Dense(1))\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Callbacks for learning rate adjustment and early stopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\n\nmodel.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test),\n          verbose=1, callbacks=[lr_scheduler, early_stopping])\n\n\n\n# Make predictions\n\npredicted_values = model.predict(X_test)\n\npredicted_values = scaler_target.inverse_transform(predicted_values)  # Inverse transform to original scale\n\ny_test_original = scaler_target.inverse_transform(y_test)  # Inverse transform for comparison\n\n\n\n# Plot the results\n\nplt.figure(figsize=(12, 6))\n\nplt.lineplot(y_test_original, label='Actual Revenue AC Output', color='blue')\n\nplt.lineplot(predicted_values, label='Predicted Revenue AC Output', color='red')\n\nplt.title('LSTM Predictions vs Actual Revenue AC Output')\n\nplt.xlabel('Time Step')\n\nplt.ylabel('Revenue AC Output')\n\nplt.legend()\n\nplt.show()\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:13:41.788313Z\",\"iopub.status.idle\":\"2024-11-12T04:13:41.788802Z\",\"shell.execute_reply.started\":\"2024-11-12T04:13:41.788547Z\",\"shell.execute_reply\":\"2024-11-12T04:13:41.788572Z\"}}\nimport pandas as pd\n\n# Assume `data` is your DataFrame\ndf_1.to_csv('f_df_1.csv', index=False)\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:13:41.790106Z\",\"iopub.status.idle\":\"2024-11-12T04:13:41.790665Z\",\"shell.execute_reply.started\":\"2024-11-12T04:13:41.790377Z\",\"shell.execute_reply\":\"2024-11-12T04:13:41.790404Z\"}}\ndf_1_Y.to_csv('f_df_1_y.csv', index=False)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:13:41.792599Z\",\"iopub.status.idle\":\"2024-11-12T04:13:41.793074Z\",\"shell.execute_reply.started\":\"2024-11-12T04:13:41.792835Z\",\"shell.execute_reply\":\"2024-11-12T04:13:41.792859Z\"}}\ndf_18.to_csv('f_df_18.csv', index=False)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:13:41.794523Z\",\"iopub.status.idle\":\"2024-11-12T04:13:41.795012Z\",\"shell.execute_reply.started\":\"2024-11-12T04:13:41.794745Z\",\"shell.execute_reply\":\"2024-11-12T04:13:41.794770Z\"}}\ndf_18_jan_clean.to_csv('f_df_18_jan_clean.csv', index=False)\n\n# %% [code] {\"id\":\"28YCZjjFWbOt\",\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:13:41.796556Z\",\"iopub.status.idle\":\"2024-11-12T04:13:41.796895Z\",\"shell.execute_reply.started\":\"2024-11-12T04:13:41.796720Z\",\"shell.execute_reply\":\"2024-11-12T04:13:41.796744Z\"}}\n# THIS IS THE INNITIAL\n\n\nimport numpy as np\n\nimport pandas as pd\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import LSTM, Dense\n\nimport matplotlib.pyplot as plt\n\n\n\n# Extract efficiency columns\n\nefficiency_cols = [f\"{i:02d}_efficiency %\" for i in range(1, 25) if i != 5]\n\nfeature_cols = efficiency_cols + ['poa_irradiance', 'ambient_temp', 'wind_speed']\n\ntarget_col = 'revenue_ac_output'\n\n\n\n# Drop rows with missing values in the selected columns\n\ndf_lstm = df_1[feature_cols + [target_col]].dropna()\n\n\n\n# Normalize the features and target separately\n\nscaler_features = MinMaxScaler(feature_range=(0, 1))\n\nscaler_target = MinMaxScaler(feature_range=(0, 1))\n\n\n\nnormalized_features = scaler_features.fit_transform(df_lstm[feature_cols])\n\nnormalized_target = scaler_target.fit_transform(df_lstm[[target_col]])\n\n\n\n# Create sequences for LSTM input\n\nsequence_length = 30  # Length of sequences (e.g., last 30 timesteps)\n\nX = []\n\ny = []\n\n\n\nfor i in range(sequence_length, len(normalized_features)):\n\n    X.append(normalized_features[i-sequence_length:i])  # Past `sequence_length` timesteps for input\n\n    y.append(normalized_target[i])  # Target at the next timestep\n\n\n\nX = np.array(X)\n\ny = np.array(y)\n\n\n\n# Manually split data into training and testing sets (e.g., 80% for training and 20% for testing)\n\ntrain_size = int(0.8 * len(X))\n\nX_train, X_test = X[:train_size], X[train_size:]\n\ny_train, y_test = y[:train_size], y[train_size:]\n\n\n\n# Build the LSTM model\n\nmodel = Sequential()\n\nmodel.add(LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n\nmodel.add(LSTM(32))\n\nmodel.add(Dense(1))  # Output layer for predicting `revenue_ac_output`\n\n\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n\n\n# Train the model\n\nmodel.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n\n\n\n# Make predictions\n\npredicted_values = model.predict(X_test)\n\npredicted_values = scaler_target.inverse_transform(predicted_values)  # Inverse transform to original scale\n\ny_test_original = scaler_target.inverse_transform(y_test)  # Inverse transform for comparison\n\n\n\n# Plot the results\n\nplt.figure(figsize=(12, 6))\n\nplt.plot(y_test_original, label='Actual Revenue AC Output', color='blue')\n\nplt.plot(predicted_values, label='Predicted Revenue AC Output', color='red')\n\nplt.title('LSTM Predictions vs Actual Revenue AC Output')\n\nplt.xlabel('Time Step')\n\nplt.ylabel('Revenue AC Output')\n\nplt.legend()\n\nplt.show()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-11-12T04:13:41.798187Z\",\"iopub.status.idle\":\"2024-11-12T04:13:41.798554Z\",\"shell.execute_reply.started\":\"2024-11-12T04:13:41.798383Z\",\"shell.execute_reply\":\"2024-11-12T04:13:41.798401Z\"}}\n# Save the entire model\nmodel.save('lstm_model_new.h5')\nh\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-11-12T05:20:12.789269Z\",\"iopub.execute_input\":\"2024-11-12T05:20:12.789667Z\",\"iopub.status.idle\":\"2024-11-12T05:20:25.027858Z\",\"shell.execute_reply.started\":\"2024-11-12T05:20:12.789622Z\",\"shell.execute_reply\":\"2024-11-12T05:20:25.026920Z\"}}\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Load the saved model\nmodel = load_model(\"/kaggle/input/lstm/tensorflow2/default/1/lstm_model_new.h5\")\n\n# Ensure that X_test is in the correct shape\n# The model expects 3D input (samples, timesteps, features)\n# Assuming that X_test is already prepared in this shape\n\n# Make predictions\npredicted_values = model.predict(X_test)\n\n# If you scaled the target values, inverse transform them to the original scale\n# Assuming `scaler_target` was used to scale the target data for `y`\npredicted_values_original = scaler_target.inverse_transform(predicted_values)\n\n# Optionally, inverse-transform the test target values for comparison\ny_test_original = scaler_target.inverse_transform(y_test)\n\n# Plotting the results (optional)\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 6))\nplt.plot(y_test_original, label='Actual Revenue AC Output', color='blue')\nplt.plot(predicted_values_original, label='Predicted Revenue AC Output', color='red')\nplt.title('LSTM Predictions vs Actual Revenue AC Output')\nplt.xlabel('Time Step')\nplt.ylabel('Revenue AC Output')\nplt.legend()\nplt.show()\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-11-12T05:29:17.455532Z\",\"iopub.execute_input\":\"2024-11-12T05:29:17.456218Z\",\"iopub.status.idle\":\"2024-11-12T05:29:17.490805Z\",\"shell.execute_reply.started\":\"2024-11-12T05:29:17.456167Z\",\"shell.execute_reply\":\"2024-11-12T05:29:17.489646Z\"}}\nX_test.head()\n\n# %% [code]\n","metadata":{"_uuid":"04740ccc-5959-4e44-9213-78aaacb84c40","_cell_guid":"24c638d4-1f27-4044-97a6-fb23202cf51f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}